<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>All You Need to Know About Big O Notation [Python Examples] | Polymath.cloud</title>

<meta name="keywords" content="Computer Science, Datastructures and Algorithms" />
<meta name="description" content="By the end of this article, you&rsquo;ll thoroughly understand Big O notation. You&rsquo;ll also know how to use it in the real world, and even the mathematics behind it!
In computer science, time complexity is the computational complexity that describes the amount of time it takes to run an algorithm.
Big O notation is a method for determining how fast an algorithm is. Using Big O notation, we can learn whether our algorithm is fast or slow.">
<meta name="author" content="Bee">
<link rel="canonical" href="https://polymath.cloud/big-o-notation/" />
<link href="https://polymath.cloud/assets/css/stylesheet.min.94a69f3d0b70cac76c6d6f7dfecc9f91f2319ec73d54be960b0d3624fa5a25e2.css" integrity="sha256-lKafPQtwysdsbW99/syfkfIxnsc9VL6WCw02JPpaJeI=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="https://polymath.cloud/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://polymath.cloud/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://polymath.cloud/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://polymath.cloud/apple-touch-icon.png">
<link rel="mask-icon" href="https://polymath.cloud/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.68.3" />



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload='renderMathInElement(document.body, { delimiters: [ {left: "$$", right: "$$", display: true}, {left: "$", right: "$", display: false}, {left: "\\(", right: "\\)", display: false}, {left: "\\[", right: "\\]", display: true} ] });'></script>


<style>
    td, th {
    border: thin solid #999 !important;
    padding: 12px 15px;
}

thead tr {
    background-color: #009879;
    color: #ffffff;
    text-align: left;
}

table {
    border-collapse: collapse;
    margin: 25px 0;
    font-size: 0.9em;
    font-family: sans-serif;
    min-width: 400px;
    overflow: auto;
    display: table;
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
}

tbody tr {
    border-bottom: thin solid #dddddd;
}


tbody tr:last-of-type {
    border-bottom: 2px solid #009879;
}

tbody td.active-item {
    font-weight: bold;
    color: #009879;
}

tbody tr:nth-of-type(even) {
    background-color: #f3f3f3;
    }


body.dark tbody tr:nth-of-type(even) {
    background-color: #383838;
}


img {
    display: block;
    margin: auto;
    text-align: center;
}

</style>
<meta property="og:title" content="All You Need to Know About Big O Notation [Python Examples]" />
<meta property="og:description" content="By the end of this article, you&rsquo;ll thoroughly understand Big O notation. You&rsquo;ll also know how to use it in the real world, and even the mathematics behind it!
In computer science, time complexity is the computational complexity that describes the amount of time it takes to run an algorithm.
Big O notation is a method for determining how fast an algorithm is. Using Big O notation, we can learn whether our algorithm is fast or slow." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://polymath.cloud/big-o-notation/" />
<meta property="article:published_time" content="2020-10-08T16:43:37+00:00" />
<meta property="article:modified_time" content="2020-10-08T16:43:37+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="All You Need to Know About Big O Notation [Python Examples]"/>
<meta name="twitter:description" content="By the end of this article, you&rsquo;ll thoroughly understand Big O notation. You&rsquo;ll also know how to use it in the real world, and even the mathematics behind it!
In computer science, time complexity is the computational complexity that describes the amount of time it takes to run an algorithm.
Big O notation is a method for determining how fast an algorithm is. Using Big O notation, we can learn whether our algorithm is fast or slow."/>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "All You Need to Know About Big O Notation [Python Examples]",
  "name": "All You Need to Know About Big O Notation [Python Examples]",
  "description": "By the end of this article, you\u0026amp;rsquo;ll thoroughly understand Big O notation. You\u0026amp;rsquo;ll also know how to use it in the real world, and even the mathematics behind it!\nIn ‚Ä¶",
  "keywords": [
    "Computer Science", "Datastructures and Algorithms"
  ],
  "articleBody": "By the end of this article, you‚Äôll thoroughly understand Big O notation. You‚Äôll also know how to use it in the real world, and even the mathematics behind it!\nIn computer science, time complexity is the computational complexity that describes the amount of time it takes to run an algorithm.\nBig O notation is a method for determining how fast an algorithm is. Using Big O notation, we can learn whether our algorithm is fast or slow. This knowledge lets us design better algorithms.\nThis article is written using agnostic Python. That means it will be easy to port the Big O notation code over to Java, or any other language. If the code isn‚Äôt agnostic, there‚Äôs Java code accompanying it.\n‚ùì How Do We Measure How Long an Algorithm Takes to Run? We could run an algorithm 10,000 times and measure the average time taken.\n‚ûú python3 -m timeit '[print(x) for x in range(100)]' 100 loops, best of 3: 11.1 msec per loop ‚ûú python3 -m timeit '[print(x) for x in range(10)]' 1000 loops, best of 3: 1.09 msec per loop # We can see that the time per loop changes depending on the input! Say we have an algorithm that takes a shopping list and prints out every item on the shopping list. If the shopping list has 3 items, it‚Äôll execute quickly. If it has 10 billion items, it‚Äôll take a long time.\nWhat is the ‚Äúperfect‚Äù input size to get the ‚Äúperfect‚Äù measure of how long the algorithm takes?\nOther things we need to consider:\n Different processor speeds exist. Languages matter. Assembly is faster than Scratch; how do we consider this?  For this reason, we use Big O (pronounced Big Oh) notation. ü§î What Is Big O Notation? /media/bigo/big_o_constant_time-1.png\nBig O is a formal notation that describes the behaviour of a function when the argument tends towards the maximum input. It was invented by Paul Bachmann, Edmund Landau and others between 1894 and 1820s. Popularised in the 1970s by Donald Knuth. Big O takes the upper bound. The worst-case results in the worst execution of the algorithm. For our shopping list example, the worst-case is an infinite list.\nInstead of saying the input is 10 billion, or infinite - we say the input is n size. The exact size of the input doesn‚Äôt matter, only how our algorithm performs with the worst input. We can still work out Big O without knowing the exact size of an input.\nBig O is easy to read once we learn this table: The Big O Notation‚Äôs Order of GrowthConstant Logarithm Linear Polynomial Exponential\n The Big O Notation's Order of Growth      Constant   Logarithm   Linear   Polynomial   Exponential    O($1$) O($log\\;n$) O($n$) O($n^2$), O($n^3$), O($n^x$) O($2^n$)    Where the further right they are, the longer it takes. n is the size of the input. Big O notation uses these functions to describe algorithm efficiency.\nIn our shopping list example, in the worst-case of our algorithm it prints out every item in the list sequentially. Since there are n items in the list, it takes $O(n)$ polynomial time to complete the algorithm.\nOther asymptotic (time-measuring) notations are:\n Asymptotic Notation      Big Omega (lower bound)  Big Theta (average bound)  Big O (max bound)   $\\omega (n)$  $\\theta (n)$ $O(n)$    Informally this is:\n Big Omega (best case) Big Theta (average case) Big O (worst case)  Let‚Äôs walk through every single column in our ‚ÄúThe Big O Notation Table‚Äù.\nüü¢ Constant Time No matter how many elements, it will always take x operations to perform. In this case, 2. Constant algorithms do not scale with the input size, they are constant no matter how big the input. An example of this is addition. $1 + 2$ takes the same time as $500 + 700$. They may take more *physical time, *but we do not add more steps in the algorithm for addition of big numbers. The underlying algorithm doesn‚Äôt change at all.\nWe often see constant as $O(1)$, but any number could be used and it would still be constant. We sometimes change the number to a 1, because it doesn‚Äôt matter at all about how many steps it takes. What matters is that it takes a constant number of steps.\nConstant time is the fastest of all Big O time complexities. The formal definition of constant time is:\n It is upper-bounded by a constant\n An example is:\ndef OddOrEven(n): return \"Even\" if n % 2 else \"Odd\" Or in Java:\nboolean isEven(double num) { return ((num % 2) == 0); } In most programming languages, all integers have limits. Primitive operations (such as modulo, %) are all upper-bounded by this limit. If we go over this limit, we get an overflow error.\nBecause of this upper-bound, it satisfies $O(1)$.\nüîµ Logarithmic Time Here‚Äôs a quick explainer of what a logarithm is.\n$$Log_{3}^{9}$$\nWhat is being asked here is ‚Äú3 to what power gives us 9?‚Äù This is 3 to the power of 2 gives us 9, so the whole expression looks like:\n$$Log_{3}^{9} = 2$$\nA logarithmic algorithm **halves **the list every time it‚Äôs run.\nLet‚Äôs look at binary search. Given the below sorted list:\na = [1, 2, 3, 4, 5, 6 , 7, 8, 9, 10] We want to find the number ‚Äú2‚Äù.\nWe implement Binary Search as:\ndef binarySearch(alist, item): first = 0 last = len(alist)-1 found = False while first  last and not found: midpoint = (first + last)//2 if alist[midpoint] == item: found = True else: if item  alist[midpoint]: last = midpoint-1 else: first = midpoint+1 return found In English this is:\n Go to the middle of the list Check to see if that element is the answer If it‚Äôs not, check to see if that element is more than the item we want to find If it is, ignore the right-hand side (all the numbers higher than the midpoint) of the list and choose a new midpoint. Start over again, by finding the midpoint in the new list.  binary_search_gif\nThe algorithm halves the input every single time it iterates. Therefore it is logarithmic. Other examples include:\n Fibonacci number calculations Searching a Binary Search Tree Searching AVL trees  üü° Linear Time Linear time algorithms mean that every single element from the input is visited exactly once, O(n) times. As the size of the input, N, grows our algorithm‚Äôs run time scales exactly with the size of the input.\n Linear running time algorithms are widespread. Linear runtime means that the program visits every element from the input. Linear time complexity O(n) means that as the input grows, the algorithms take proportionally longer to complete.2 Apr 2019\n Remember our shopping list app from earlier? The algorithm ran in O(n) which is linear time!\nLinear time is where every single item in a list is visited once, in a worst-case scenario.\nTo read out our shopping list, our algorithm has to read out each item. It can‚Äôt half the list, or add more items that we didn‚Äôt add. It has to list all n items, one at a time.\nshopping_list = [\"Bread\", \"Butter\", \"The Nacho Libre soundtrack from the 2006 film Nacho Libre\", \"Reusable Water Bottle\"] for item in shopping_list: print(item) Let‚Äôs look at another example.\nThe largest item of an unsorted array Given the list:\na = [2, 16, 7, 9, 8, 23, 12] How do we work out what the largest item is?\nWe need to program it like this:\na = [2, 16, 7, 9, 8, 23, 12] max_item = a[0] for item in a: if item  max_item: max_item = item We have to go through every item in the list, 1 by 1.\nüî¥ Polynomial Time Notice how polynomial time dwarfs the others? Polynomial time is a polynomial function of the input. A polynomial function looks like $n^2$ or $n^3$ and so on.\nIf one loop through a list is $O(n)$, 2 loops must be $O(n^2)$. For each loop, we go over the list once. For each item in that list, we go over the entire list once. Resulting in n2 operations.\na = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] for i in a: for x in a: print(\"x\") For each nesting on the same list, that adds an extra +1 onto the powers.\nA triple nested loop is $O(n^3)$.\nBubblesort is a good example of an $O(n^2)$ algorithm. The sorting algorithm takes the first number and swaps it with the adjacent number if they are in the wrong order. It does this for each number, until all numbers are in the right order - and thus sorted.\ndef bubbleSort(arr): n = len(arr) # Traverse through all array elements for i in range(n): # Last i elements are already in place for j in range(0, n-i-1): # traverse the array from 0 to n-i-1 # Swap if the element found is greater # than the next element if arr[j]  arr[j+1] : arr[j], arr[j+1] = arr[j+1], arr[j] # Driver code to test above arr = [64, 34, 25, 12, 22, 11, 90] bubbleSort(arr) As a side note, my professor refers to any algorithm with a time of polynomial or above as:\n A complete and utter disaster! This is a disaster! A catastrophe!\n But the thing with large time complexities is that they often show us that something can be quickened.\nFor instance, a problem I had. Given a sentence, how many of those words appear in the English Dictionary? We can imagine the $O(n^2)$ method. One for loop through the sentence, another through the dictionary.\ndictionary = [\"a\", \"an\"] # imagine if this was the dictionary sentence = \"hello uu988j my nadjjrjejas is brandon nanndwifjasj banana\".split(\" \") counter = 0 for word in sentence: for item in dictionary: if word == item: counter = counter + 1 $O(n^2)$! A disaster! But, knowing that this is a disaster means we can speed it up. Dictionaries are sorted by default. What if we sort our list of words in the sentence, and checked each word that way? We only need to loop through the dictionary once. And if the word we want to check is less than the word we‚Äôre on in the dictionary, we switch to the second word in the list.\nNow our algorithm is $O(n ; log ; n)$. We recognise that this isn‚Äôt a disaster, so we can move on! Knowing time complexities isn‚Äôt only useful in interviews. It‚Äôs an essential tool to improve our algorithms.\nWe can hasten many polynomial algorithms we construct using knowledge of algorithmic design.\n‚ùå Exponential Time Exponential time is $2^n$, where 2 depends on the permutations involved.\nThis algorithm is the slowest of them all. You saw how my professor reacted to polynomial algorithms. He was jumping up and down in furiosity at exponential algorithms!\nSay we have a password consisting only of numbers (so that‚Äôs 10 numbers, 0 through to 9). we want to crack a password which has a length of n, so to bruteforce through every combination we‚Äôll have:\n$$10^n$$\nCombinations to work through.\nOne example of exponential time is to find all the subsets of a set.\n subsets(['']) ['']  subsets(['x']) ['', 'x']  subsets(['a', 'b']) ['', 'a', 'b', 'ab'] We can see that when we have an input size of 2, the output size is $2^2 = 4$.\nNow, let‚Äôs code up subsets.\nfrom itertools import chain, combinations def subsets(iterable): s = list(iterable) return chain.from_iterable(combinations(s, r) for r in range(len(s)+1)) Taken from the documentation for itertools.\nWhat‚Äôs important here is to see that it exponentially grows depending on the input size. Java code can be found here.\nExponential algorithms are horrific, but like polynomial algorithms we can learn a thing or two. Let‚Äôs say we have to calculate $10^4$. We need to do this:\n$$10 * 10 * 10 * 10 = 10^2 * 10^2$$\nWe have to calculate $10^2$ twice! What if we store that value somewhere and use it later so we do not have to recalculate it? This is the principle of Dynamic Programming, which you can read about here.\nWhen we see an exponential algorithm, dynamic programming can often be used to speed it up.\nAgain, knowing time complexities allows us to build better algorithms.\nHere‚Äôs our Big O notation graph where the numbers are reduced so we can see all the different lines.\n üòå Simplifying Big O notation Rarely will time complexity be as easy as counting how many for loops we have. What if our algorithm looks like $O(n + n^2)$? We can simplify our algorithm using these simple rules:\nDrop the constants If we have an algorithm described as $O(2n)$, we drop the $2$ so it becomes $O(n)$.\nDrop the non-dominant terms $O(n¬≤ + n)$ becomes $O(n¬≤)$. Only keep the larger one in Big O.\nIf we have a sum such as $O(b¬≤ + a)$ we can‚Äôt drop either without knowledge of what b and a are.\nIs that it? Yup! The hardest part is figuring out what our program‚Äôs complexity is first. Simplifying is the easy part! Just remember the golden rule of Big O notation:\n ‚ÄúWhat is the worst-case scenario here?‚Äù\n  ‚òÅ Other Big O Times to Learn (But Not Essential) ü•á O(n log n) It falls between O(n) and O(n2) This is the fastest time possible for a comparison sort. We cannot get any faster unless we use some special property, like Radix sort. O($n ; log ; n$) is the fastest comparison sort time.\nIt‚Äôs rather famous, because Mergesort runs in O($n ; log ; n$). Mergesort is a great algorithm not only because it sorts fast, but because the idea is used to build other algorithms.\nMergesort is used to teach divide \u0026 conquer algorithms. And for good reason, it‚Äôs a fantastic sorting algorithm that has roots outside of sorting.\nMergesort works by breaking down the list of numbers into individual numbers:\ndef mergeSort(alist): print(\"Splitting \",alist) if len(alist)1: mid = len(alist)//2 lefthalf = alist[:mid] righthalf = alist[mid:] mergeSort(lefthalf) mergeSort(righthalf) i=0 j=0 k=0 while i  len(lefthalf) and j  len(righthalf): if lefthalf[i]  righthalf[j]: alist[k]=lefthalf[i] i=i+1 else: alist[k]=righthalf[j] j=j+1 k=k+1 while i  len(lefthalf): alist[k]=lefthalf[i] i=i+1 k=k+1 while j  len(righthalf): alist[k]=righthalf[j] j=j+1 k=k+1 print(\"Merging \",alist) alist = [54,26,93,17,77,31,44,55,20] mergeSort(alist) print(alist) Read more on Mergesort here.\nüëø O(n!) This one is so large, it makes all other times look constant!\nThis time complexity is often used as a joke, referring to Bogo Sort. I have yet to find a real life (not-a-joke) algorithm that runs in O(n!) that isn‚Äôt an algorithm calculating O(6!) or the likes.\n üßÆ How to Calculate Big O Notation for Our Own Algorithms with Examples Our own algorithms will normally be based on some famous algorithm that already has a Big O notation. If it‚Äôs not, do not worry! Working out the Big O of our algorithm is easy.\nJust think:\n ‚ÄúWhat is the absolute worst input for my program?‚Äù\n Take, for instance, a sequential searching algorithm.\ndef search(listInput, toFind): for counter, item in enumerate(listInput): if toFind == item: return (counter, item) return \"did not find the item!\" The best input would be:\nsearch([\"apples\"], \"apples\") But the worst input is if the item was at the end of a long list.\nsearch([\"apples\", \"oranges\", \"The soundtrack from the 2006 film Nacho Libre\", \"Shrek\"], \"Shrek\") The worst-case scenario is $O(n)$, because we have to go past every item in the list to find it.\nWhat if our search algorithm was binary search? We learnt that binary search divides the list into half everytime. This sounds like log n!\nWhat if our binary search looks for an object, and then looks to find other similar objects?\n# here we want to find the film shrek, find its IMDB rating and find other films with that IMDB rating. We are using binary search, then sequential search toFind = {title: \"Shrek\", IMDBrating: None} ret = search(toFind) ret = search(ret['IMDBrating']) We find Shrek with an IMDB score of 7.8. But we‚Äôre only sorted on the title, not the IMDB rating. We have to use sequential search to find all other films with the same rating.\nBinary search is $O(log ; n)$ and sequential search is $O(n)$, this makes our algorithm $O(n ; log ; n)$. This isn‚Äôt a disaster, so we can sure it‚Äôs not a terrible algorithm.\nEven in the instances where our algorithms are not strictly related to other algorithms, we can still compare them to things we know. $O(log ; n)$ means halfing. $O(n^2)$ means a nested for loop.\nOne last thing, we don‚Äôt always deal with n. Take this below algorithm:\nx = [1, 2, 3, 4, 5] y = [2, 6] y = iter(y) counter = 0 total = 0.0 while counter != len(x): # cycles through the y list. # multiplies 2 by 1, then 6 by 2. Then 2 by 3.  total = total + x[counter] * next(y) counter += 1 print(total) We have 2 inputs, x and y. Our notation is then $$O(x + y)$$. Sometimes we cannot make our notation smaller without knowing more about the data.\n ü§Ø Big O Notation Cheat Sheet I made this little infographic for you! The ‚Äúadd +1 for every nested for loop‚Äù depends on the for loop, as we saw earlier. But explaining that all over again would take up too much space üòÖ\n üéì How to Calculate Big O Notation of a Function (Discrete Maths) Okay, this is where it gets hard. A lot of complaints against Big O notation is along the lines of:\n ‚ÄúYou didn‚Äôt really teach it, to really understand it you have to understand the maths!‚Äù\n And I kinda agree. The surface level knowledge above will be good for most interviews, but the stuff here is the stuff needed to master Big O notation.\nJust as a reminder, we want to master asymptotic time complexity as it allows us to create better algorithms.\nI‚Äôm going to be writing out the formal notation, and then explaining it simply. Over-simplification causes misinformation, so if you are studying for a test take my simplifications as generalities and not the truth. The mathematics is the whole truth, and you would be better of studying the maths rather than studying my simplifications. As I once read on the internet:\n Shut up and calculate.\n Is Big O Notation the Worst-Case? First things first, when I said:\n Big O notation is the worst-case\n That‚Äôs not true at all. It‚Äôs a white lie designed to help you learn the basics. Often used to get us to know enough to just pass interviews, but not enough to use it in the real world.\nThe formal definition of Big O notation is:\n The upper-bounded time limit of the algorithm\n Now, this often means ‚Äúthe worst-case‚Äù but not always. We can put upper bounds on whatever we want. But more often than not, we put upper-bounds on the worst-case. In one of our examples, we‚Äôll come across a weird formula where ‚Äúthe worst-case‚Äù isn‚Äôt necessarily the one we choose for Big O.\nThis is an important distinction to make, because some caveats will confuse us otherwise.\nGiven 2 positive functions, $f(n)$ and $g(n)$ we say $f(n)$ is $O(g(n))$, written $f(n) \\in O(g(n))$, if there are constants $c$ and $n_0$ such that:\n$$f(n) \\le c * g(n) \\forall ;n \\geq n_o$$\nSide note: Asymptotic notation leans heavily into set theory. Check out my article on set theory here.\nAlso, sometimes $n_0$ is called $k$. But $c$ stays the same.\nThis looks confusing, but is just a fancy way of saying that the function (algorithm) is a part of another function (the Big O notation used). Simplifying again: Our algorithm falls within the range of a Big O notation time complexity (O(n), O(log n), etc). So our algorithm is that time complexity (to simplify it).\nLet‚Äôs see an example.\n$$7n - 4 \\in O(n)$$\nHere we are claiming that $7n - 4$ is in $O(n)$ time. In formal Big O notation, we don‚Äôt say it is that time. We say it falls within the range of that time.\nWe need to find constants $c$ and $n_0$ such that $7n-4 \\le cn$ for all $n \\geq n_0$.\nOne choice is $c = 7$ and $n_0 = 1$. $7 * 7 = 42 - 4 = 38$ and $7 * 1 = 7$ so for all where $n \\geq 7$ this function holds true.\nThis is just one of the many choices, because any real number $c \\geq 7$ and any integer $n_0 \\geq 1$ would be okay.\nAnother way to rephrase this is:\n$$7n-4 \\le 7n ; where ; n \\geq 1$$\nThe left hand side, $7n-4$ is f(n). c = 10. g(n) = n. Therefore we can say $f(n) =O(n)$ because $g(n) = n$. We say $f(n) \\in O(n)$.\nAll we have to do is substitute values into the formula until we find values for c and n that work. Let‚Äôs do 10 examples now.\nExample 1 $$f(n) = 4n^2 + 16n + 2$$\n Is f(n) O(n4)?\n We need to take this function:\n$$f(n) = 4n^2 + 16n + 2$$\nand say ‚Äúis this less than some constant times $n^4$?‚Äù We need to find out if there is such a constant.\n$$n^2 + 16n + 2 \\le n^4$$\nLet‚Äôs do a chart. If $n = 0$ we get:\n$$0 + 0 + 2 = 2 \\le 0$$\nThis isn‚Äôt true, so N = 0 is not true.\nWhen $n = 1$:\n$$ 4 * 1 * 16 * 2 = 22 \\le 1^4 = 22 \\le 1$$\nIs not true. Let‚Äôs try it again with n = 3.\n$$50 \\le 16$$\nNot true, so let‚Äôs try another one. $n = 3$.\n$$86 \\le 3^3 = 86 \\le 81$$\nNot true. Looks like the next one should work as we are approaching the tipping point. $n = 4$.\n$$ 130 \\le 256$$\nThis is true. When $n = 4$ or a greater number then this function where it‚Äôs less than N4 becomes True. When $C = 1, N \\geq 4$ this holds true.\nThe answer to the question ‚Äúis this function, $n^2 + 16n + 2$, Big O of n4 true?‚Äù Yes, when $c = 1$ and $n \\geq 4$.‚Äù\nNote: I‚Äôm saying $c=1$ but I‚Äôm not writing $cn$ every time. Later on, using c will become important. But for these starter examples we‚Äôll just assume $c = 1$ until said otherwise.\nExample 2 $$3n^2 + n + 16$$\n Is this $O(n^2)$?\n We know that $n \\le n^2$ for all $n \\geq 1$. Also, $16 \\le n^2$ for $n \\geq 4$.\nSo: $$3n^2 + n + 16 \\le 3n^2 + n^2 + n^2 = 5n^2$$\nfor all $n \\geq 4$. The constant C is 5, and $n_0 = 3$.\nExample 3 $$13n^3 + 7n ;log ;n + 3$$\n is $O(n^3)$\n Because $log ;n \\le n \\geq n^2$ for all $n \\geq 1$, and for similar reasons as above we may conclude that:\n$13n^3 + 6nlog ;n + 3 \\le 21 n^3$ for all ‚Äòlarge enough‚Äô n.\nIn this instance, $c = 21$.\nExample 4 $$45n^5 - 10n^2 + 6n - 12$$\n is $O(n^2)$?\n Any polynomial $a_k n^k + ‚Ä¶ + a_2 n^2 + a_1 n + a_0$ with $a_k  0$ is $O(n^k)$.\nAlong the same lines, we can arrgue that any polynomial $a_k n^k + ‚Ä¶ + a_2 n^2 + a_1 n + a-0$ with $a_k  0$ is also $O(n^j)$ for all $j \\geq k$.\nTherefore $45n^5 - 10n^2 + 6n - 12$ is $O(n^2)$ (and is also $O(n^8)$ or $O(n^9)$ or $O(n^k)$ for any $n \\geq 5$).\nExample 5 $$\\sqrt{n}$$\n is $O(n)$?\n This doesn‚Äôt hold true. $\\sqrt{n} = n^{1/2}$. Therefore $O(n^{1/2}) I hope you appreciate the easy example to break up the hard maths üòâ\nExample 6 $$ 3 ;log ;n + ;log ;log ;n$$\n is $O(log ;n)$?\n First we have this equality that $log ;n \\le n$ for every $n \\geq 1$. We can put a double log here like so: $log;log;n \\le log ;n$. Log log n is smaller than log n. We replaced ‚Äún‚Äù with ‚Äúlog n‚Äù on both sides of $log ;n \\le n$. So:\n$$3 ;log ;n + ;log;log ;n \\le 4 ;log ;n$$\nSo:\n$$c = 4, n_0 = 1$$\nExample 7 $log ; n$\n is $Log n grows slower than any function where this holds:\n$$log ; m \\le m^\\epsilon$$ for every $\\epsilon  0$ no matter how small it is, as long as it is positive.\nUsing this inequality if we plug in $\\epsilon = \\frac{1}{2}$ and we plug that into our equation $\\sqrt{m} = m^{\\frac{1}{2}}$.\nKnowing that $log ; m \\le m^\\epsilon$ we know that $O(log ; n) Example 8 $$2n + 3$$\n What is the Big O of this?\n $$2n + 3 \\le 10n, n \\geq 1$$\n$$f(n) = O(n)$$.\nThis is because n is more than or equal to 1, it will always be larger than g(n) which is $2n + 3$. Therefore, we have $O(n)$.\nExample 9 $$2n + 3 \\le 10n$$\nWe don‚Äôt have to write 10, it can be whatever we want so long as the equation holds true.\n$$2n + 3 \\le 2n + 3n$$\n$$2n + 3 \\le 5n, n \\geq 1$$\nTherefore $f(n) = O(n)$.\nOr we can write:\n$$2n + 3 \\le 5n^2 , n \\geq 1$$\n$$f(n) = 2n + 3$$\n$$c = 5$$\n$$g(n) = n^2$$\nCan this same function be both $O(n)$ and $O(n^2)$? Yes. It can be. This is where our definition of big o comes into play. It‚Äôs the upperbounded limit. We can say it is $n^2, 2^n$ and any higher. But we cannot say it‚Äôs lower.\nWhen we write big o, we often want to use the closet function. Otherwise we could say that every algorithm has an upperbound of $O(2^n)$, which isn‚Äôt true. Note: what we want to do (choose the closet function) is just personal preference for most courses. All functions which work, which are the upperbound, are true.\nThere‚Äôs a fantastic video on this strange concept here (and I took this example from there).\n üëã Summary Big O represents how long an algorithm takes but sometimes we care about how much memory (space complexity) an algorithm takes too. If you‚Äôre ever stuck, come back to this page and check out the infographics!\n",
  "wordCount" : "4392",
  "inLanguage": "en",
  "datePublished": "2020-10-08T16:43:37Z",
  "dateModified": "2020-10-08T16:43:37Z",
  "author":{
    "@type": "Person",
    "name": "Bee"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://polymath.cloud/big-o-notation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Polymath.cloud",
    "logo": {
      "@type": "ImageObject",
      "url": "https://polymath.cloud/favicon.ico"
    }
  }
}
</script>



</head>

<body class="">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        .theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://polymath.cloud" accesskey="h">Polymath.cloud</a>
            <span class="logo-switches">
                <span class="theme-toggle">
                    <a id="theme-toggle" accesskey="t">
                        <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                        </svg>
                        <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <circle cx="12" cy="12" r="5"></circle>
                            <line x1="12" y1="1" x2="12" y2="3"></line>
                            <line x1="12" y1="21" x2="12" y2="23"></line>
                            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                            <line x1="1" y1="12" x2="3" y2="12"></line>
                            <line x1="21" y1="12" x2="23" y2="12"></line>
                            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                        </svg>
                    </a>
                </span>
                
            </span>
        </div>
        <ul class="menu" id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://polymath.cloud/archives" title="Archive">
                    <span>
                        Archive
                    </span>
                </a>
            </li>
            <li>
                <a href="https://polymath.cloud/search/" title="Search">
                    <span>
                        Search
                    </span>
                </a>
            </li>
            <li>
                <a href="https://polymath.cloud/tags/" title="Tags">
                    <span>
                        Tags
                    </span>
                </a>
            </li></ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">
      All You Need to Know About Big O Notation [Python Examples]
    </h1>
    <div class="post-meta">

October 8, 2020&nbsp;¬∑&nbsp;21 min&nbsp;¬∑&nbsp;Bee

    </div>
  </header> 

  <div class="toc">
    <details >
      <summary>
        <div class="details" accesskey="c">Table of Contents</div>
      </summary>
      <blockquote><ul><ul><li>
        <a href="#-how-do-we-measure-how-long-an-algorithm-takes-to-run" aria-label="‚ùì How Do We Measure How Long an Algorithm Takes to Run?">‚ùì How Do We Measure How Long an Algorithm Takes to Run?</a></li><li>
        <a href="#for-this-reason-we-use-big-o-pronounced-big-oh-notation" aria-label="For this reason, we use Big O (pronounced Big Oh) notation.">For this reason, we use Big O (pronounced Big Oh) notation.</a></li><li>
        <a href="#-what-is-big-o-notation" aria-label="ü§î What Is Big O Notation?">ü§î What Is Big O Notation?</a></li><li>
        <a href="#-constant-time" aria-label="üü¢ Constant Time">üü¢ Constant Time</a></li><li>
        <a href="#-logarithmic-time" aria-label="üîµ Logarithmic Time">üîµ Logarithmic Time</a></li></ul>
        <li>
        <a href="#-linear-time" aria-label="üü° Linear Time">üü° Linear Time</a><ul>
            <ul>
            <li>
        <a href="#the-largest-item-of-an-unsorted-array" aria-label="The largest item of an unsorted array">The largest item of an unsorted array</a></li></ul>
        <li>
        <a href="#-polynomial-time" aria-label="üî¥ Polynomial Time">üî¥ Polynomial Time</a></li><li>
        <a href="#-exponential-time" aria-label="‚ùå Exponential Time">‚ùå Exponential Time</a></li><li>
        <a href="#-simplifying-big-o-notation" aria-label="üòå Simplifying Big O notation">üòå Simplifying Big O notation</a><ul>
            <li>
        <a href="#drop-the-constants" aria-label="Drop the constants">Drop the constants</a></li><li>
        <a href="#drop-the-non-dominant-terms" aria-label="Drop the non-dominant terms">Drop the non-dominant terms</a></li><li>
        <a href="#is-that-it" aria-label="Is that it?">Is that it?</a></li></ul>
    </li><li>
        <a href="#-other-big-o-times-to-learn-but-not-essential" aria-label="‚òÅ Other Big O Times to Learn (But Not Essential)">‚òÅ Other Big O Times to Learn (But Not Essential)</a><ul>
            <li>
        <a href="#-on-log-n" aria-label="ü•á O(n log n)">ü•á O(n log n)</a></li><li>
        <a href="#-on" aria-label="üëø O(n!)">üëø O(n!)</a></li></ul>
    </li><li>
        <a href="#-how-to-calculate-big-o-notation-for-our-own-algorithms-with-examples" aria-label="üßÆ How to Calculate Big O Notation for Our Own Algorithms with Examples">üßÆ How to Calculate Big O Notation for Our Own Algorithms with Examples</a></li></ul>
    </li><li>
        <a href="#-big-o-notation-cheat-sheet" aria-label="ü§Ø Big O Notation Cheat Sheet">ü§Ø Big O Notation Cheat Sheet</a><ul>
            <li>
        <a href="#-how-to-calculate-big-o-notation-of-a-function-discrete-maths" aria-label="üéì How to Calculate Big O Notation of a Function (Discrete Maths)">üéì How to Calculate Big O Notation of a Function (Discrete Maths)</a><ul>
            <li>
        <a href="#is-big-o-notation-the-worst-case" aria-label="Is Big O Notation the Worst-Case?">Is Big O Notation the Worst-Case?</a></li><li>
        <a href="#example-1" aria-label="Example 1">Example 1</a></li><li>
        <a href="#example-2" aria-label="Example 2">Example 2</a></li><li>
        <a href="#example-3" aria-label="Example 3">Example 3</a></li><li>
        <a href="#example-4" aria-label="Example 4">Example 4</a></li><li>
        <a href="#example-5" aria-label="Example 5">Example 5</a></li><li>
        <a href="#example-6" aria-label="Example 6">Example 6</a></li><li>
        <a href="#example-7" aria-label="Example 7">Example 7</a></li><li>
        <a href="#example-8" aria-label="Example 8">Example 8</a></li><li>
        <a href="#example-9" aria-label="Example 9">Example 9</a></li></ul>
    </li><li>
        <a href="#-summary" aria-label="üëã Summary">üëã Summary</a></li></ul>
</li></ul>
      </blockquote>
    </details>
  </div>
  <div class="post-content">
<p>By the end of this article, you&rsquo;ll thoroughly understand Big O notation. You&rsquo;ll also know how to use it in the real world, and even the mathematics behind it!</p>
<p>In computer science, <strong>time complexity</strong> is the computational <strong>complexity</strong> that describes the amount of <strong>time</strong> it takes to run an algorithm.</p>
<p>Big O notation is a method for determining how fast an algorithm is. Using Big O notation, we can learn whether our algorithm is fast or slow. This knowledge lets us design better algorithms.</p>
<p>This article is written using agnostic Python. That means it will be easy to port the Big O notation code over to Java, or any other language. If the code isn&rsquo;t agnostic, there&rsquo;s Java code accompanying it.</p>
<!-- raw HTML omitted -->
<h2 id="-how-do-we-measure-how-long-an-algorithm-takes-to-run">‚ùì How Do We Measure How Long an Algorithm Takes to Run?<a hidden class="anchor" aria-hidden="true" href="#-how-do-we-measure-how-long-an-algorithm-takes-to-run">#</a></h2>
<p><img src="/media/bigo/undraw_1.svg" alt=""></p>
<!-- raw HTML omitted -->
<p>We could run an algorithm 10,000 times and measure the average time taken.</p>
<pre><code class="language-console" data-lang="console">‚ûú python3 -m timeit '[print(x) for x in range(100)]'
100 loops, best of 3: 11.1 msec per loop 
‚ûú python3 -m timeit '[print(x) for x in range(10)]'
1000 loops, best of 3: 1.09 msec per loop
# We can see that the time per loop changes depending on the input!
</code></pre><p>Say we have an algorithm that takes a shopping list and prints out every item on the shopping list. If the shopping list has 3 items, it&rsquo;ll execute quickly. If it has 10 billion items, it&rsquo;ll take a long time.</p>
<p>What is the ‚Äúperfect‚Äù input size to get the ‚Äúperfect‚Äù measure of how long the algorithm takes?</p>
<p>Other things we need to consider:</p>
<ul>
<li>Different processor speeds exist.</li>
<li>Languages matter. Assembly is faster than Scratch; how do we consider this?</li>
</ul>
<h2 id="for-this-reason-we-use-big-o-pronounced-big-oh-notation">For this reason, we use Big O (pronounced Big Oh) notation.<a hidden class="anchor" aria-hidden="true" href="#for-this-reason-we-use-big-o-pronounced-big-oh-notation">#</a></h2>
<h2 id="-what-is-big-o-notation">ü§î What Is Big O Notation?<a hidden class="anchor" aria-hidden="true" href="#-what-is-big-o-notation">#</a></h2>
<p><img src="/media/bigo/undraw_2.svg" alt=""></p>
<p>/media/bigo/big_o_constant_time-1.png</p>
<p>Big O is a formal notation that describes the behaviour of a function when the argument tends towards the maximum input. It was invented by <a href="https://www-history.mcs.st-andrews.ac.uk/Biographies/Bachmann.html">Paul Bachmann</a>, <a href="https://en.wikipedia.org/wiki/Edmund_Landau">Edmund Landau</a> and others between 1894 and 1820s. Popularised in the 1970s by <a href="https://www-cs-faculty.stanford.edu/~knuth/">Donald Knuth</a>. Big O takes the upper bound. The worst-case results in the worst execution of the algorithm. For our shopping list example, the worst-case is an infinite list.</p>
<p>Instead of saying the input is 10 billion, or infinite - we say the input is n size. The exact size of the input doesn&rsquo;t matter, only how our algorithm performs with the worst input. We can still work out Big O without knowing the exact size of an input.</p>
<p>Big O is easy to read once we learn this table:
The Big O Notation&rsquo;s Order of GrowthConstant Logarithm Linear Polynomial Exponential</p>


<table style="font-size: 18px;">
    <thead style="font-size: 0;">
        <tr>
            <th colspan="5" style="font-size: 20px; text-transform: capitalize;"><center>The Big O Notation's Order of Growth<center></th>
        </tr>
    </thead>
    <tbody>
      <tr>
        <td> <strong>Constant </td>
        <td> <strong>Logarithm </td>
        <td> <strong>Linear </td>
        <td> <strong>Polynomial </td>
        <td> <strong>Exponential </td>
      </tr>
        <tr>
            <td>O($1$)</td>
            <td>O($log\;n$)</td>
            <td>O($n$)</td>
          <td>O($n^2$), O($n^3$), O($n^x$)</td>
          <td>O($2^n$)</td>
        </tr>

    </tbody>
</table>



<p>Where the further right they are, the longer it takes. <code>n</code> is the size of the input. Big O notation uses these functions to describe algorithm efficiency.</p>
<p>In our shopping list example, in the worst-case of our algorithm it prints out every item in the list sequentially. Since there are <code>n</code> items in the list, it takes $O(n)$ polynomial time to complete the algorithm.</p>
<p>Other asymptotic (time-measuring) notations are:</p>


<table style="font-size: 18px;">
    <thead style="font-size: 0;">
        <tr>
            <th colspan="3" style="font-size: 20px; text-transform: capitalize;"><center>Asymptotic Notation<center></th>
        </tr>
    </thead>
    <tbody>
      <tr>
        <td> <strong>Big Omega (lower bound)</td>
                    <td> <strong>Big Theta (average bound)</td>

        <td> <strong>Big O (max bound)</td>
      </tr>
        <tr>
            <td>$\omega (n)$ </td>
            <td>$\theta (n)$</td>
            <td>$O(n)$</td>
            
        </tr>

    </tbody>
</table>


<p><strong>Informally</strong> this is:</p>
<ul>
<li>Big Omega (best case)</li>
<li>Big Theta (average case)</li>
<li>Big O (worst case)</li>
</ul>
<p>Let&rsquo;s walk through every single column in our &ldquo;The Big O Notation Table&rdquo;.</p>
<h2 id="-constant-time">üü¢ Constant Time<a hidden class="anchor" aria-hidden="true" href="#-constant-time">#</a></h2>
<p><img src="/media/bigo/big_o_constant_time-1.png" alt=""></p>
<!-- raw HTML omitted -->
<p>No matter how many elements, it will always take x operations to perform. In this case, 2.
Constant algorithms do not scale with the input size, they are constant no matter how big the input. An example of this is addition. $1 + 2$ takes the same time as $500 + 700$. They may take more *physical time, *but we do not add more steps in the algorithm for addition of big numbers. The underlying algorithm doesn&rsquo;t change at all.</p>
<p>We often see constant as $O(1)$, but any number could be used and it would still be constant. We sometimes change the number to a 1, because it doesn&rsquo;t matter at all about how many steps it takes. What matters is that it takes a constant number of steps.</p>
<p>Constant time is the fastest of all Big O time complexities. The formal definition of constant time is:</p>
<blockquote>
<p>It is upper-bounded by a constant</p>
</blockquote>
<p>An example is:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">OddOrEven</span>(n):
    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;Even&#34;</span> <span style="color:#66d9ef">if</span> n <span style="color:#f92672">%</span> <span style="color:#ae81ff">2</span> <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;Odd&#34;</span>
</code></pre></div><p>Or in Java:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#66d9ef">boolean</span> <span style="color:#a6e22e">isEven</span><span style="color:#f92672">(</span><span style="color:#66d9ef">double</span> num<span style="color:#f92672">)</span> <span style="color:#f92672">{</span> <span style="color:#66d9ef">return</span> <span style="color:#f92672">((</span>num <span style="color:#f92672">%</span> 2<span style="color:#f92672">)</span> <span style="color:#f92672">==</span> 0<span style="color:#f92672">);</span> <span style="color:#f92672">}</span>
</code></pre></div><p>In most programming languages, all integers have limits. Primitive operations (such as modulo, <code>%</code>) are all upper-bounded by this limit. If we go over this limit, we get an overflow error.</p>
<p>Because of this upper-bound, it satisfies $O(1)$.</p>
<h2 id="-logarithmic-time">üîµ Logarithmic Time<a hidden class="anchor" aria-hidden="true" href="#-logarithmic-time">#</a></h2>
<!-- raw HTML omitted -->
<p>Here&rsquo;s a quick explainer of what a logarithm is.</p>
<p>$$Log_{3}^{9}$$</p>
<p>What is being asked here is ‚Äú3 to what power gives us 9?‚Äù This is 3 to the power of 2 gives us 9, so the whole expression looks like:</p>
<p>$$Log_{3}^{9} = 2$$</p>
<p>A logarithmic algorithm **halves **the list every time it‚Äôs run.</p>
<p>Let&rsquo;s look at binary search. Given the below sorted list:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">a <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span> , <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">10</span>]
</code></pre></div><p>We want to find the number &ldquo;2&rdquo;.</p>
<p>We implement Binary Search as:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">binarySearch</span>(alist, item):
    first <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    last <span style="color:#f92672">=</span> len(alist)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
    found <span style="color:#f92672">=</span> False

    <span style="color:#66d9ef">while</span> first <span style="color:#f92672">&lt;=</span> last <span style="color:#f92672">and</span> <span style="color:#f92672">not</span> found:
        midpoint <span style="color:#f92672">=</span> (first <span style="color:#f92672">+</span> last)<span style="color:#f92672">//</span><span style="color:#ae81ff">2</span>
        <span style="color:#66d9ef">if</span> alist[midpoint] <span style="color:#f92672">==</span> item:
            found <span style="color:#f92672">=</span> True
        <span style="color:#66d9ef">else</span>:
            <span style="color:#66d9ef">if</span> item <span style="color:#f92672">&lt;</span> alist[midpoint]:
            last <span style="color:#f92672">=</span> midpoint<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
            <span style="color:#66d9ef">else</span>:
                first <span style="color:#f92672">=</span> midpoint<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>

    <span style="color:#66d9ef">return</span> found
</code></pre></div><p>In English this is:</p>
<ul>
<li>Go to the middle of the list</li>
<li>Check to see if that element is the answer</li>
<li>If it&rsquo;s not, check to see if that element is more than the item we want to find</li>
<li>If it is, ignore the right-hand side (all the numbers higher than the midpoint) of the list and choose a new midpoint.</li>
<li>Start over again, by finding the midpoint in the new list.</li>
</ul>
<p>binary_search_gif</p>
<!-- raw HTML omitted -->
<p>The algorithm halves the input every single time it iterates. Therefore it is logarithmic. Other examples include:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/program-for-nth-fibonacci-number/">Fibonacci number calculations</a></li>
<li><a href="https://en.wikipedia.org/wiki/Binary_search_tree">Searching a Binary Search Tree</a></li>
<li><a href="https://www.cs.auckland.ac.nz/software/AlgAnim/AVL.html">Searching AVL trees</a></li>
</ul>
<h1 id="-linear-time">üü° Linear Time<a hidden class="anchor" aria-hidden="true" href="#-linear-time">#</a></h1>
<!-- raw HTML omitted -->
<p>Linear time algorithms mean that every single element from the input is visited exactly once, O(n) times. As the size of the input, N, grows our algorithm&rsquo;s run time scales exactly with the size of the input.</p>
<blockquote>
<p><strong>Linear</strong> running <strong>time algorithms</strong> are widespread. <strong>Linear</strong> runtime means that the program visits every element from the input. <strong>Linear time</strong> complexity O(n) means that as the input grows, the <strong>algorithms</strong> take proportionally longer to complete.2 Apr 2019</p>
</blockquote>
<p>Remember our shopping list app from earlier? The algorithm ran in O(n) which is linear time!</p>
<p>Linear time is where every single item in a list is visited once, in a worst-case scenario.</p>
<p>To read out our shopping list, our algorithm <strong>has</strong> to read out each item. It can&rsquo;t half the list, or add more items that we didn&rsquo;t add. It has to list all n items, one at a time.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">shopping_list <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;Bread&#34;</span>, <span style="color:#e6db74">&#34;Butter&#34;</span>, <span style="color:#e6db74">&#34;The Nacho Libre soundtrack from the 2006 film Nacho Libre&#34;</span>, <span style="color:#e6db74">&#34;Reusable Water Bottle&#34;</span>]
<span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> shopping_list:
    <span style="color:#66d9ef">print</span>(item)
</code></pre></div><p>Let&rsquo;s look at another example.</p>
<h3 id="the-largest-item-of-an-unsorted-array">The largest item of an unsorted array<a hidden class="anchor" aria-hidden="true" href="#the-largest-item-of-an-unsorted-array">#</a></h3>
<p>Given the list:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">a <span style="color:#f92672">=</span> [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">23</span>, <span style="color:#ae81ff">12</span>]
</code></pre></div><p>How do we work out what the largest item is?</p>
<p>We need to program it like this:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">a <span style="color:#f92672">=</span> [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">23</span>, <span style="color:#ae81ff">12</span>]
max_item <span style="color:#f92672">=</span> a[<span style="color:#ae81ff">0</span>]
<span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> a:
    <span style="color:#66d9ef">if</span> item <span style="color:#f92672">&gt;</span> max_item:
        max_item <span style="color:#f92672">=</span> item
</code></pre></div><p>We have to go through every item in the list, 1 by 1.</p>
<h2 id="-polynomial-time">üî¥ Polynomial Time<a hidden class="anchor" aria-hidden="true" href="#-polynomial-time">#</a></h2>
<!-- raw HTML omitted -->
<p>Notice how polynomial time dwarfs the others?
Polynomial time is a polynomial function of the input. A polynomial function looks like $n^2$ or $n^3$ and so on.</p>
<p>If one loop through a list is $O(n)$, 2 loops must be $O(n^2)$. For each loop, we go over the list once. For each item in that list, we go over the entire list once. Resulting in n2 operations.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">a <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">10</span>]
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> a:
    <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> a:
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;x&#34;</span>)
</code></pre></div><p>For each nesting on the same list, that adds an extra +1 onto the powers.</p>
<p>A triple nested loop is $O(n^3)$.</p>
<p>Bubblesort is a good example of an $O(n^2)$ algorithm. The sorting algorithm takes the first number and swaps it with the adjacent number if they are in the wrong order. It does this for each number, until all numbers are in the right order - and thus sorted.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bubbleSort</span>(arr):
    n <span style="color:#f92672">=</span> len(arr)
    
    <span style="color:#75715e"># Traverse through all array elements</span>
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(n):
    
        <span style="color:#75715e"># Last i elements are already in place</span>
        <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, n<span style="color:#f92672">-</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>):
    
            <span style="color:#75715e"># traverse the array from 0 to n-i-1</span>
            <span style="color:#75715e"># Swap if the element found is greater</span>
            <span style="color:#75715e"># than the next element</span>
            <span style="color:#66d9ef">if</span> arr[j] <span style="color:#f92672">&gt;</span> arr[j<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] :
                arr[j], arr[j<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> arr[j<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>], arr[j]
    
<span style="color:#75715e"># Driver code to test above</span>
arr <span style="color:#f92672">=</span> [<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">34</span>, <span style="color:#ae81ff">25</span>, <span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">22</span>, <span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">90</span>]
    
bubbleSort(arr)
</code></pre></div><!-- raw HTML omitted -->
<p>As a side note, my professor refers to any algorithm with a time of polynomial or above as:</p>
<blockquote>
<p>A complete and utter disaster! This is a disaster! A catastrophe!</p>
</blockquote>
<p>But the thing with large time complexities is that they often show us that something can be quickened.</p>
<p>For instance, a problem I had. Given a sentence, how many of those words appear in the English Dictionary? We can imagine the $O(n^2)$ method. One <code>for loop</code> through the sentence, another through the dictionary.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dictionary <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;a&#34;</span>, <span style="color:#e6db74">&#34;an&#34;</span>] <span style="color:#75715e"># imagine if this was the dictionary</span>
sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;hello uu988j my nadjjrjejas is brandon nanndwifjasj banana&#34;</span><span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34; &#34;</span>)

counter <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> sentence:
    <span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> dictionary:
        <span style="color:#66d9ef">if</span> word <span style="color:#f92672">==</span> item:
            counter <span style="color:#f92672">=</span> counter <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</code></pre></div><p>$O(n^2)$! A disaster! But, knowing that this is a disaster means we can speed it up. Dictionaries are sorted by default. What if we sort our list of words in the sentence, and checked each word that way? We only need to loop through the dictionary once. And if the word we want to check is less than the word we&rsquo;re on in the dictionary, we switch to the second word in the list.</p>
<p>Now our algorithm is $O(n ; log ; n)$. We recognise that this isn&rsquo;t a disaster, so we can move on! <strong>Knowing time complexities isn&rsquo;t only useful in interviews. It&rsquo;s an essential tool to improve our algorithms.</strong></p>
<p>We can hasten many polynomial algorithms we construct using knowledge of <a href="https://skerritt.blog/dynamic-programming/">algorithmic design</a>.</p>
<h2 id="-exponential-time">‚ùå Exponential Time<a hidden class="anchor" aria-hidden="true" href="#-exponential-time">#</a></h2>
<!-- raw HTML omitted -->
<p>Exponential time is $2^n$, where 2 depends on the permutations involved.</p>
<p>This algorithm is the slowest of them all. You saw how my professor reacted to polynomial algorithms. He was jumping up and down in furiosity at exponential algorithms!</p>
<p>Say we have a password consisting only of numbers (so that‚Äôs 10 numbers, 0 through to 9). we want to crack a password which has a length of n, so to bruteforce through every combination we&rsquo;ll have:</p>
<p>$$10^n$$</p>
<p>Combinations to work through.</p>
<p>One example of exponential time is to <a href="https://skerritt.blog/a-primer-on-set-theory/">find all the subsets of a set.</a></p>
<pre><code class="language-console" data-lang="console">&gt;&gt;&gt; subsets([''])
['']
&gt;&gt;&gt; subsets(['x'])
['', 'x']
&gt;&gt;&gt; subsets(['a', 'b'])
['', 'a', 'b', 'ab']
</code></pre><p>We can see that when we have an input size of 2, the output size is $2^2 = 4$.</p>
<p>Now, let&rsquo;s code up <code>subsets</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> itertools <span style="color:#f92672">import</span> chain, combinations

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">subsets</span>(iterable):
    s <span style="color:#f92672">=</span> list(iterable)
    <span style="color:#66d9ef">return</span> chain<span style="color:#f92672">.</span>from_iterable(combinations(s, r) <span style="color:#66d9ef">for</span> r <span style="color:#f92672">in</span> range(len(s)<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>))
</code></pre></div><p><a href="https://docs.python.org/3/library/itertools.html#itertools-recipes">Taken from the documentation for itertools.</a></p>
<p>What&rsquo;s important here is to see that it exponentially grows depending on the input size. <a href="https://www.geeksforgeeks.org/power-set/">Java code can be found here.</a></p>
<p>Exponential algorithms are horrific, but like polynomial algorithms we can learn a thing or two. Let&rsquo;s say we have to calculate $10^4$. We need to do this:</p>
<p>$$10 * 10 * 10 * 10 = 10^2 * 10^2$$</p>
<p>We have to calculate $10^2$ twice! What if we store that value somewhere and use it later so we do not have to recalculate it? <a href="https://skerritt.blog/dynamic-programming/">This is the principle of Dynamic Programming, which you can read about here.</a></p>
<p>When we see an exponential algorithm, <a href="https://skerritt.blog/dynamic-programming/">dynamic programming</a> can often be used to speed it up.</p>
<p>Again, <strong>knowing time complexities allows us to build better algorithms.</strong></p>
<p>Here&rsquo;s our Big O notation graph where the numbers are reduced so we can see all the different lines.</p>
<!-- raw HTML omitted -->
<hr>
<h2 id="-simplifying-big-o-notation">üòå Simplifying Big O notation<a hidden class="anchor" aria-hidden="true" href="#-simplifying-big-o-notation">#</a></h2>
<p><img src="/media/bigo/simplfy.svg" alt=""></p>
<p>Rarely will time complexity be as easy as counting how many for loops we have. What if our algorithm looks like $O(n + n^2)$? We can simplify our algorithm using these simple rules:</p>
<h3 id="drop-the-constants">Drop the constants<a hidden class="anchor" aria-hidden="true" href="#drop-the-constants">#</a></h3>
<p>If we have an algorithm described as $O(2n)$, we drop the $2$ so it becomes $O(n)$.</p>
<h3 id="drop-the-non-dominant-terms">Drop the non-dominant terms<a hidden class="anchor" aria-hidden="true" href="#drop-the-non-dominant-terms">#</a></h3>
<p>$O(n¬≤ + n)$ becomes $O(n¬≤)$. Only keep the larger one in Big O.</p>
<p>If we have a sum such as $O(b¬≤ + a)$ we can‚Äôt drop either without knowledge of what b and a are.</p>
<h3 id="is-that-it">Is that it?<a hidden class="anchor" aria-hidden="true" href="#is-that-it">#</a></h3>
<p>Yup! The hardest part is figuring out what our program&rsquo;s complexity is first. Simplifying is the easy part! Just remember the golden rule of Big O notation:</p>
<blockquote>
<p>&ldquo;What is the worst-case scenario here?&rdquo;</p>
</blockquote>
<hr>
<h2 id="-other-big-o-times-to-learn-but-not-essential">‚òÅ Other Big O Times to Learn (But Not Essential)<a hidden class="anchor" aria-hidden="true" href="#-other-big-o-times-to-learn-but-not-essential">#</a></h2>
<h3 id="-on-log-n">ü•á O(n log n)<a hidden class="anchor" aria-hidden="true" href="#-on-log-n">#</a></h3>
<!-- raw HTML omitted -->
<p>It falls between O(n) and O(n2)
<strong>This is the fastest time possible for a comparison sort.</strong> We cannot get any faster unless we use some special property, like Radix sort. O($n ; log ; n$) is the fastest comparison sort time.</p>
<p>It&rsquo;s rather famous, because Mergesort runs in O($n ; log ; n$). Mergesort is a great algorithm not only because it sorts fast, but because the idea is used to build other algorithms.</p>
<p>Mergesort is used to teach <a href="https://skerritt.blog/divide-and-conquer-algorithms/">divide &amp; conquer algorithms</a>. And for good reason, it&rsquo;s a fantastic sorting algorithm that has roots outside of sorting.</p>
<p>Mergesort works by breaking down the list of numbers into individual numbers:</p>
<!-- raw HTML omitted -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">mergeSort</span>(alist):
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Splitting &#34;</span>,alist)
    <span style="color:#66d9ef">if</span> len(alist)<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">1</span>:
        mid <span style="color:#f92672">=</span> len(alist)<span style="color:#f92672">//</span><span style="color:#ae81ff">2</span>
        lefthalf <span style="color:#f92672">=</span> alist[:mid]
        righthalf <span style="color:#f92672">=</span> alist[mid:]

        mergeSort(lefthalf)
        mergeSort(righthalf)

        i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
        j<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
        k<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
        <span style="color:#66d9ef">while</span> i <span style="color:#f92672">&lt;</span> len(lefthalf) <span style="color:#f92672">and</span> j <span style="color:#f92672">&lt;</span> len(righthalf):
            <span style="color:#66d9ef">if</span> lefthalf[i] <span style="color:#f92672">&lt;=</span> righthalf[j]:
                alist[k]<span style="color:#f92672">=</span>lefthalf[i]
                i<span style="color:#f92672">=</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>
            <span style="color:#66d9ef">else</span>:
                alist[k]<span style="color:#f92672">=</span>righthalf[j]
                j<span style="color:#f92672">=</span>j<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>
            k<span style="color:#f92672">=</span>k<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>

        <span style="color:#66d9ef">while</span> i <span style="color:#f92672">&lt;</span> len(lefthalf):
            alist[k]<span style="color:#f92672">=</span>lefthalf[i]
            i<span style="color:#f92672">=</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>
            k<span style="color:#f92672">=</span>k<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>

        <span style="color:#66d9ef">while</span> j <span style="color:#f92672">&lt;</span> len(righthalf):
            alist[k]<span style="color:#f92672">=</span>righthalf[j]
            j<span style="color:#f92672">=</span>j<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>
            k<span style="color:#f92672">=</span>k<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Merging &#34;</span>,alist)

alist <span style="color:#f92672">=</span> [<span style="color:#ae81ff">54</span>,<span style="color:#ae81ff">26</span>,<span style="color:#ae81ff">93</span>,<span style="color:#ae81ff">17</span>,<span style="color:#ae81ff">77</span>,<span style="color:#ae81ff">31</span>,<span style="color:#ae81ff">44</span>,<span style="color:#ae81ff">55</span>,<span style="color:#ae81ff">20</span>]
mergeSort(alist)
<span style="color:#66d9ef">print</span>(alist)
</code></pre></div><p><a href="https://skerritt.blog/divide-and-conquer-algorithms#merge-sort-">Read more on Mergesort here.</a></p>
<h3 id="-on">üëø O(n!)<a hidden class="anchor" aria-hidden="true" href="#-on">#</a></h3>
<!-- raw HTML omitted -->
<p>This one is so large, it makes all other times look constant!</p>
<p>This time complexity is often used as a joke, referring to Bogo Sort. I have yet to find a real life (not-a-joke) algorithm that runs in O(n!) that isn&rsquo;t an algorithm calculating O(6!) or the likes.</p>
<hr>
<h2 id="-how-to-calculate-big-o-notation-for-our-own-algorithms-with-examples">üßÆ How to Calculate Big O Notation for Our Own Algorithms with Examples<a hidden class="anchor" aria-hidden="true" href="#-how-to-calculate-big-o-notation-for-our-own-algorithms-with-examples">#</a></h2>
<p><img src="/media/bigo/calculate.svg" alt=""></p>
<p>Our own algorithms will normally be based on some famous algorithm that already has a Big O notation. If it&rsquo;s not, do not worry! Working out the Big O of our algorithm is easy.</p>
<p>Just think:</p>
<blockquote>
<p>&ldquo;What is the absolute worst input for my program?&rdquo;</p>
</blockquote>
<p>Take, for instance, a sequential searching algorithm.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">search</span>(listInput, toFind):
    <span style="color:#66d9ef">for</span> counter, item <span style="color:#f92672">in</span> enumerate(listInput):
        <span style="color:#66d9ef">if</span> toFind <span style="color:#f92672">==</span> item:
            <span style="color:#66d9ef">return</span> (counter, item)
    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;did not find the item!&#34;</span>
</code></pre></div><p>The best input would be:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">search([<span style="color:#e6db74">&#34;apples&#34;</span>], <span style="color:#e6db74">&#34;apples&#34;</span>)
</code></pre></div><p>But the worst input is if the item was at the end of a long list.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">search([<span style="color:#e6db74">&#34;apples&#34;</span>, <span style="color:#e6db74">&#34;oranges&#34;</span>, <span style="color:#e6db74">&#34;The soundtrack from the 2006 film Nacho Libre&#34;</span>, <span style="color:#e6db74">&#34;Shrek&#34;</span>], <span style="color:#e6db74">&#34;Shrek&#34;</span>)
</code></pre></div><p>The worst-case scenario is $O(n)$, because we have to go past every item in the list to find it.</p>
<p>What if our search algorithm was binary search? We learnt that binary search divides the list into half everytime. This sounds like <code>log n</code>!</p>
<p>What if our binary search looks for an object, and then looks to find other similar objects?</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># here we want to find the film shrek, find its IMDB rating and find other films with that IMDB rating. We are using binary search, then sequential search</span>
toFind <span style="color:#f92672">=</span> {title: <span style="color:#e6db74">&#34;Shrek&#34;</span>, IMDBrating: None}
ret <span style="color:#f92672">=</span> search(toFind)
ret <span style="color:#f92672">=</span> search(ret[<span style="color:#e6db74">&#39;IMDBrating&#39;</span>])
</code></pre></div><p>We find Shrek with an IMDB score of 7.8. But we&rsquo;re only sorted on the title, not the IMDB rating. We have to use sequential search to find all other films with the same rating.</p>
<p>Binary search is $O(log ; n)$ and sequential search is $O(n)$, this makes our algorithm $O(n ; log ; n)$. This isn&rsquo;t a disaster, so we can sure it&rsquo;s not a terrible algorithm.</p>
<p>Even in the instances where our algorithms are not strictly related to other algorithms, we can still compare them to things we know. $O(log ; n)$ means halfing. $O(n^2)$ means a nested for loop.</p>
<p>One last thing, we don&rsquo;t always deal with <code>n</code>. Take this below algorithm:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>]
y <span style="color:#f92672">=</span> [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">6</span>]
y <span style="color:#f92672">=</span> iter(y)
counter <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
total <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
<span style="color:#66d9ef">while</span> counter <span style="color:#f92672">!=</span> len(x):
    <span style="color:#75715e"># cycles through the y list.</span>
    <span style="color:#75715e"># multiplies 2 by 1, then 6 by 2. Then 2 by 3. </span>
    total <span style="color:#f92672">=</span> total <span style="color:#f92672">+</span> x[counter] <span style="color:#f92672">*</span> next(y)
    counter <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
<span style="color:#66d9ef">print</span>(total)
</code></pre></div><p>We have 2 inputs, x and y. Our notation is then $$O(x + y)$$. Sometimes we cannot make our notation smaller without knowing more about the data.</p>
<hr>
<h1 id="-big-o-notation-cheat-sheet">ü§Ø Big O Notation Cheat Sheet<a hidden class="anchor" aria-hidden="true" href="#-big-o-notation-cheat-sheet">#</a></h1>
<p>I made this little infographic for you! The &ldquo;add +1 for every nested for loop&rdquo; depends on the for loop, as we saw earlier. But explaining that all over again would take up too much space üòÖ</p>
<p><img src="/media/bigo/cheatsheet.png" alt="">
<img src="/media/bigo/cheatsheet2.png" alt=""></p>
<hr>
<h2 id="-how-to-calculate-big-o-notation-of-a-function-discrete-maths">üéì How to Calculate Big O Notation of a Function (Discrete Maths)<a hidden class="anchor" aria-hidden="true" href="#-how-to-calculate-big-o-notation-of-a-function-discrete-maths">#</a></h2>
<p><img src="/media/bigo/hat.svg" alt=""></p>
<p>Okay, this is where it gets hard. A lot of complaints against Big O notation is along the lines of:</p>
<blockquote>
<p>&ldquo;You didn&rsquo;t really teach it, to really understand it you have to understand the maths!&rdquo;</p>
</blockquote>
<p>And I kinda agree. The surface level knowledge above will be good for most interviews, but the stuff here is the stuff needed to master Big O notation.</p>
<p>Just as a reminder, we want to master asymptotic time complexity as it allows us to create better algorithms.</p>
<p>I&rsquo;m going to be writing out the formal notation, and then explaining it simply. <strong>Over-simplification causes misinformation</strong>, so if you are studying for a test take my simplifications as generalities and not the truth. The mathematics is the whole truth, and you would be better of studying the maths rather than studying my simplifications. As I once read on the internet:</p>
<blockquote>
<p>Shut up and calculate.</p>
</blockquote>
<h3 id="is-big-o-notation-the-worst-case">Is Big O Notation the Worst-Case?<a hidden class="anchor" aria-hidden="true" href="#is-big-o-notation-the-worst-case">#</a></h3>
<p>First things first, when I said:</p>
<blockquote>
<p>Big O notation is the worst-case</p>
</blockquote>
<p><strong>That&rsquo;s not true at all</strong>. It&rsquo;s a white lie designed to help you learn the basics. Often used to get us to know enough to <em>just</em> pass interviews, but not enough to use it in the real world.</p>
<p>The formal definition of Big O notation is:</p>
<blockquote>
<p>The upper-bounded time limit of the algorithm</p>
</blockquote>
<p>Now, this often means &ldquo;the worst-case&rdquo; but not always. We can put upper bounds on whatever we want. But more often than not, we put upper-bounds on the worst-case. In one of our examples, we&rsquo;ll come across a weird formula where &ldquo;the worst-case&rdquo; isn&rsquo;t necessarily the one we choose for Big O.</p>
<p>This is an important distinction to make, because some caveats will confuse us otherwise.</p>
<p>Given 2 positive functions, $f(n)$ and $g(n)$ we say $f(n)$ is $O(g(n))$, written $f(n) \in O(g(n))$, if there are constants $c$ and $n_0$ such that:</p>
<p>$$f(n) \le c * g(n) \forall ;n \geq ¬†n_o$$</p>
<p><em><a href="https://skerritt.blog/a-primer-on-set-theory/">Side note: Asymptotic notation leans heavily into set theory. Check out my article on set theory here.</a></em></p>
<p>Also, sometimes $n_0$ is called $k$. But $c$ stays the same.</p>
<p>This looks confusing, but is just a fancy way of saying that the function (algorithm) is a part of another function (the Big O notation used). Simplifying again: Our algorithm falls within the range of a Big O notation time complexity (O(n), O(log n), etc). So our algorithm <em>is</em> that time complexity (to simplify it).</p>
<p>Let&rsquo;s see an example.</p>
<p>$$7n - 4 \in O(n)$$</p>
<p>Here we are claiming that $7n - 4$ is in $O(n)$ time. In formal Big O notation, we don&rsquo;t say it <strong>is</strong> that time. We say it falls within the range of that time.</p>
<p>We need to find constants $c$ and $n_0$ such that $7n-4 \le cn$ for all $n \geq n_0$.</p>
<p>One choice is $c = 7$ and $n_0 = 1$. $7 * 7 = 42 - 4 = 38$ and $7 * 1 = 7$ so for all where $n \geq 7$ this function holds true.</p>
<p>This is just one of the many choices, because any real number $c \geq 7$ and any integer $n_0 \geq 1$ would be okay.</p>
<p>Another way to rephrase this is:</p>
<p>$$7n-4 \le 7n ; where ; n \geq 1$$</p>
<p>The left hand side, $7n-4$ is f(n). c = 10. g(n) = n. Therefore we can say $f(n) =O(n)$ because $g(n) = n$. We say $f(n) \in O(n)$.</p>
<p>All we have to do is substitute values into the formula until we find values for c and n that work. Let&rsquo;s do 10 examples now.</p>
<h3 id="example-1">Example 1<a hidden class="anchor" aria-hidden="true" href="#example-1">#</a></h3>
<p>$$f(n) = 4n^2 + 16n + 2$$</p>
<blockquote>
<p>Is f(n) O(n4)?</p>
</blockquote>
<p>We need to take this function:</p>
<p>$$f(n) = 4n^2 + 16n + 2$$</p>
<p>and say &ldquo;is this less than some constant times $n^4$?&rdquo; We need to find out if there is such a constant.</p>
<p>$$n^2 + 16n + 2 \le n^4$$</p>
<p>Let&rsquo;s do a chart. If $n = 0$ we get:</p>
<p>$$0 + 0 + 2 = 2 \le 0$$</p>
<p>This isn&rsquo;t true, so N = 0 is not true.</p>
<p>When $n = 1$:</p>
<p>$$ 4 * 1 * 16 * 2 = 22 \le 1^4 = 22 \le 1$$</p>
<p>Is not true. Let&rsquo;s try it again with n = 3.</p>
<p>$$50 \le 16$$</p>
<p>Not true, so let&rsquo;s try another one. $n = 3$.</p>
<p>$$86 \le 3^3 = 86 \le 81$$</p>
<p>Not true. Looks like the next one should work as we are approaching the tipping point. $n = 4$.</p>
<p>$$ 130 \le 256$$</p>
<p>This is <strong>true. W</strong>hen $n = 4$ or a greater number then this function where it&rsquo;s less than N4 becomes True. When $C = 1, N \geq 4$ this holds true.</p>
<p>The answer to the question &ldquo;is this function, $n^2 + 16n + 2$, Big O of n4 true?&rdquo; Yes, when $c = 1$ and $n \geq 4$.&rdquo;</p>
<p>Note: I&rsquo;m saying $c=1$ but I&rsquo;m not writing $cn$ every time. Later on, using c will become important. But for these starter examples we&rsquo;ll just assume $c = 1$ until said otherwise.</p>
<h3 id="example-2">Example 2<a hidden class="anchor" aria-hidden="true" href="#example-2">#</a></h3>
<p>$$3n^2 + n + 16$$</p>
<blockquote>
<p>Is this $O(n^2)$?</p>
</blockquote>
<p>We know that $n \le n^2$ for all $n \geq 1$. Also, $16 \le n^2$ for $n \geq 4$.</p>
<p>So:
$$3n^2 + n + 16 \le 3n^2 + n^2 + n^2 = 5n^2$$</p>
<p>for all $n \geq 4$.
The constant C is 5, and $n_0 = 3$.</p>
<h3 id="example-3">Example 3<a hidden class="anchor" aria-hidden="true" href="#example-3">#</a></h3>
<p>$$13n^3 + 7n ;log ;n + 3$$</p>
<blockquote>
<p>is $O(n^3)$</p>
</blockquote>
<p>Because $log ;n \le n \geq n^2$ for all $n \geq 1$, and for similar reasons as above we may conclude that:</p>
<p>$13n^3 + 6nlog ;n + 3 \le 21 n^3$ for all &lsquo;large enough&rsquo; n.</p>
<p>In this instance, $c = 21$.</p>
<h3 id="example-4">Example 4<a hidden class="anchor" aria-hidden="true" href="#example-4">#</a></h3>
<p>$$45n^5 - 10n^2 + 6n - 12$$</p>
<blockquote>
<p>is $O(n^2)$?</p>
</blockquote>
<p>Any polynomial $a_k n^k + &hellip; + a_2 n^2 + a_1 n + a_0$ with $a_k &gt; 0$ is $O(n^k)$.</p>
<p>Along the same lines, we can arrgue that any polynomial $a_k n^k + &hellip; + a_2 n^2 + a_1 n + a-0$ with $a_k &gt; 0$ is also $O(n^j)$ for all $j \geq k$.</p>
<p>Therefore $45n^5 - 10n^2 + 6n - 12$ is $O(n^2)$ (and is also $O(n^8)$ or $O(n^9)$ or $O(n^k)$ for any $n \geq 5$).</p>
<h3 id="example-5">Example 5<a hidden class="anchor" aria-hidden="true" href="#example-5">#</a></h3>
<p>$$\sqrt{n}$$</p>
<blockquote>
<p>is $O(n)$?</p>
</blockquote>
<p>This doesn&rsquo;t hold true. $\sqrt{n} = n^{1/2}$. Therefore $O(n^{1/2}) &lt; O(n)$.</p>
<p>I hope you appreciate the easy example to break up the hard maths üòâ</p>
<h3 id="example-6">Example 6<a hidden class="anchor" aria-hidden="true" href="#example-6">#</a></h3>
<p>$$ 3 ;log ;n + ;log ;log ;n$$</p>
<blockquote>
<p>is $O(log ;n)$?</p>
</blockquote>
<p>First we have this equality that $log ;n \le n$ for every $n \geq 1$. We can put a double log here like so: $log;log;n \le log ;n$. Log log n is smaller than log n. We replaced &ldquo;n&rdquo; with &ldquo;log n&rdquo; on both sides of $log ;n \le n$. So:</p>
<p>$$3 ;log ;n + ;log;log ;n \le 4 ;log ;n$$</p>
<p>So:</p>
<p>$$c = 4, n_0 = 1$$</p>
<h3 id="example-7">Example 7<a hidden class="anchor" aria-hidden="true" href="#example-7">#</a></h3>
<p>$log ; n$</p>
<blockquote>
<p>is $&lt; O(\sqrt{n})$</p>
</blockquote>
<p>Log n grows slower than any function where this holds:</p>
<p>$$log ; m \le m^\epsilon$$ for every $\epsilon &gt; 0$ no matter how small it is, as long as it is positive.</p>
<p>Using this inequality if we plug in $\epsilon = \frac{1}{2}$ and we plug that into our equation $\sqrt{m} = m^{\frac{1}{2}}$.</p>
<p>Knowing that $log ; m \le m^\epsilon$ we know that $O(log ; n) &lt; O(\sqrt{n})$</p>
<h3 id="example-8">Example 8<a hidden class="anchor" aria-hidden="true" href="#example-8">#</a></h3>
<p>$$2n + 3$$</p>
<blockquote>
<p>What is the Big O of this?</p>
</blockquote>
<p>$$2n + 3 \le 10n, n ¬†\geq 1$$</p>
<p>$$f(n) = O(n)$$.</p>
<p>This is because n is more than or equal to 1, it will always be larger than g(n) which is $2n + 3$. Therefore, we have $O(n)$.</p>
<h3 id="example-9">Example 9<a hidden class="anchor" aria-hidden="true" href="#example-9">#</a></h3>
<p>$$2n + 3 \le 10n$$</p>
<p>We don&rsquo;t have to write 10, it can be whatever we want so long as the equation holds true.</p>
<p>$$2n + 3 \le 2n + 3n$$</p>
<p>$$2n + 3 \le 5n, n \geq 1$$</p>
<p>Therefore $f(n) = O(n)$.</p>
<p>Or we can write:</p>
<p>$$2n + 3 \le 5n^2 , n \geq 1$$</p>
<p>$$f(n) = 2n + 3$$</p>
<p>$$c = 5$$</p>
<p>$$g(n) = n^2$$</p>
<p>Can this same function be both $O(n)$ and $O(n^2)$? Yes. It can be. This is where our definition of big o comes into play. It&rsquo;s the upperbounded limit. We can say it is $n^2, 2^n$ and any higher. But we cannot say it&rsquo;s lower.</p>
<p>When we write big o, we often want to use the closet function. Otherwise we could say that every algorithm has an upperbound of $O(2^n)$, which isn&rsquo;t true. Note: what we want to do (choose the closet function) ¬†is just personal preference for most courses. All functions which work, which are the upperbound, are true.</p>
<p><a href="https://www.youtube.com/watch?v=A03oI0znAoc">There&rsquo;s a fantastic video on this strange concept here</a> (and I took this example from there).</p>
<hr>
<h2 id="-summary">üëã Summary<a hidden class="anchor" aria-hidden="true" href="#-summary">#</a></h2>
<p><img src="/media/bigo/coffee.svg" alt="">
Big O represents how long an algorithm takes but sometimes we care about how much memory (space complexity) an algorithm takes too. If you&rsquo;re ever stuck, come back to this page and check out the infographics!</p>

</div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://polymath.cloud/tags/computer-science/">Computer Science</a></li>
      <li><a href="https://polymath.cloud/tags/datastructures-and-algorithms/">Datastructures and Algorithms</a></li>
    </ul>






<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share All You Need to Know About Big O Notation [Python Examples] on twitter"
        href="https://twitter.com/intent/tweet/?text=All%20You%20Need%20to%20Know%20About%20Big%20O%20Notation%20%5bPython%20Examples%5d&amp;url=https%3a%2f%2fpolymath.cloud%2fbig-o-notation%2f&amp;hashtags=ComputerScience%2cDatastructuresandAlgorithms">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share All You Need to Know About Big O Notation [Python Examples] on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpolymath.cloud%2fbig-o-notation%2f&amp;title=All%20You%20Need%20to%20Know%20About%20Big%20O%20Notation%20%5bPython%20Examples%5d&amp;summary=All%20You%20Need%20to%20Know%20About%20Big%20O%20Notation%20%5bPython%20Examples%5d&amp;source=https%3a%2f%2fpolymath.cloud%2fbig-o-notation%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share All You Need to Know About Big O Notation [Python Examples] on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fpolymath.cloud%2fbig-o-notation%2f&title=All%20You%20Need%20to%20Know%20About%20Big%20O%20Notation%20%5bPython%20Examples%5d">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share All You Need to Know About Big O Notation [Python Examples] on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpolymath.cloud%2fbig-o-notation%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share All You Need to Know About Big O Notation [Python Examples] on whatsapp"
        href="https://api.whatsapp.com/send?text=All%20You%20Need%20to%20Know%20About%20Big%20O%20Notation%20%5bPython%20Examples%5d%20-%20https%3a%2f%2fpolymath.cloud%2fbig-o-notation%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share All You Need to Know About Big O Notation [Python Examples] on telegram"
        href="https://telegram.me/share/url?text=All%20You%20Need%20to%20Know%20About%20Big%20O%20Notation%20%5bPython%20Examples%5d&amp;url=https%3a%2f%2fpolymath.cloud%2fbig-o-notation%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main><footer class="footer">
    <span>&copy; 2020 <a href="https://polymath.cloud">Polymath.cloud</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<button class="top-link" id="top-link" type="button" aria-label="go to top" title="Go to Top" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6">
        <path d="M12 6H0l6-6z" /></svg>
</button>



<script defer src="https://polymath.cloud/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js" integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w="
    onload="hljs.initHighlightingOnLoad();"></script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
    mybutton.onclick = function () {
        document.body.scrollTop = 0;
        document.documentElement.scrollTop = 0;
        window.location.hash = ''
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
